from lambench.models.ase_models import ASEModel
from lambench.tasks.calculator.inference_efficiency.efficiency_utils import (
    binary_search_max_natoms,
    get_efv,
    find_even_factors,
)
from ase.io import read
import logging
import time
import numpy as np
from pathlib import Path

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)


def run_inference(
    model: ASEModel, test_data: Path, warmup_ratio: float
) -> dict[str, dict[str, float]]:
    """
    Inference for all trajectories, return average time and success rate for each system.
    """
    results = {}
    trajs = list(test_data.rglob("*.traj"))
    for traj in trajs:
        system_name = traj.name
        try:
            system_result = run_one_inference(model, traj, warmup_ratio)
            average_time = system_result["average_time"]
            std_time = system_result["std_time"]
            success_rate = system_result["success_rate"]
            results[system_name] = {
                "average_time": average_time,
                "std_time": std_time,
                "success_rate": success_rate,
            }
            logging.info(
                f"Inference completed for system {system_name} with average time {average_time} s and success rate {success_rate:.2f}%"
            )
        except Exception as e:
            logging.error(f"Error in inference for system {system_name}: {e}")
            results[system_name] = {
                "average_time": None,
                "std_time": None,
                "success_rate": 0.0,
            }
    return results


def run_one_inference(
    model: ASEModel,
    test_traj: Path,
    warmup_ratio: float,
) -> dict[str, float]:
    """
    Infer for one trajectory, return averaged time and success rate, starting timing at warmup_ratio.
    """
    test_atoms = read(test_traj, ":")
    start_index = int(len(test_atoms) * warmup_ratio)
    valid_steps = 0
    successful_inferences = 0
    total_inferences = len(test_atoms)

    efficiency = []
    for i, atoms in enumerate(test_atoms):
        # find maximum allowed natoms
        max_natoms = binary_search_max_natoms(model, atoms)
        # on-the-fly expand atoms
        scaling_factor = np.int32(np.floor(max_natoms / len(test_atoms)))
        while 1 in find_even_factors(scaling_factor) and scaling_factor > 1:
            scaling_factor -= 1
        a, b, c = find_even_factors(scaling_factor)
        atoms = atoms.repeat((a, b, c))
        atoms.calc = model.calc
        n_atoms = len(atoms)
        start = time.time()
        try:
            get_efv(atoms)
            successful_inferences += 1
        except Exception as e:
            logging.error(f"Error in inference for {str(atoms.symbols)}: {e}")
            continue

        end = time.time()
        elapsed_time = end - start

        if i >= start_index:
            efficiency.append(
                elapsed_time / n_atoms * 1e6
            )  # inference efficiency in Âµs/atom
            valid_steps += 1

    if valid_steps > 0:
        average_efficiency = np.mean(efficiency)
        std_efficiency = np.std(efficiency)
    else:
        average_efficiency = None
        std_efficiency = None

    if total_inferences > 0:
        success_rate = (successful_inferences / total_inferences) * 100
    else:
        success_rate = 0.0

    return {
        "average_time": average_efficiency,
        "std_time": std_efficiency,
        "success_rate": success_rate,
    }
